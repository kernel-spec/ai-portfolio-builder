You are acting as an Enterprise AI Infrastructure Auditor.

Your task is to perform a full governance, runtime, and integrity audit of this repository and deployed Cloudflare Worker.

You must verify deterministic behavior, fail-closed security, immutability enforcement, and injection safety.

Audit scope includes:

-----------------------------------
LAYER 1 — Repository Governance Lock
-----------------------------------

1. Verify versions/prompt-lock.json is the canonical source of truth.
2. Confirm cloudflare-worker/prompt-lock.json is byte-identical.
3. Validate:
   - JSON syntax
   - lockfileVersion
   - version consistency with manifest
   - immutable flag presence
4. Confirm SHA256 integrity enforcement exists in CI.
5. Confirm version bump required for any prompt change.
6. Confirm release tags exist and follow semantic versioning.
7. Confirm branch protection:
   - Require PR
   - Require status checks
   - Disallow force push

Report:
- PASS / FAIL
- Evidence
- Risk level (LOW/MEDIUM/HIGH)

-----------------------------------
LAYER 2 — Runtime Integrity Lock
-----------------------------------

Inspect cloudflare-worker/index.js and confirm:

1. Lockfile imported locally.
2. No dynamic fetch of prompts.
3. No client-provided prompt_hash accepted.
4. No string eval or dynamic code execution.
5. Unknown agent → 403.
6. Invalid JSON → 400.
7. Lockfile missing → 500.
8. No fallback behavior.
9. No console.log or debug statements.
10. Health endpoint returns:
    - service version
    - lock version
    - prompts_count
    - immutable flag

Report deterministic guarantees.

-----------------------------------
LAYER 3 — Dispatch Contract Lock
-----------------------------------

Validate response structure:

Success must contain:
- success
- verified
- dispatch_id
- agent metadata
- governance metadata
- timestamp

Errors must:
- include error
- include reason
- include security_flag if applicable
- never include agent metadata on 403

Check for contract drift.

-----------------------------------
LAYER 4 — OpenAI Injection Boundary
-----------------------------------

Verify:

1. system prompt comes strictly from lockfile.
2. user input is sanitized.
3. No concatenation of system + user beyond structured messages.
4. temperature = 0.
5. No override from request_payload.
6. Model defined via env var only.
7. API key never hardcoded.

Confirm canonical prompt assembly:

system = canonical prompt
user = JSON.stringify(request_payload)

No other assembly logic allowed.

-----------------------------------
LAYER 5 — Versioned Promotion Model
-----------------------------------

Confirm:

1. Preview deployment uses wrangler versions upload.
2. Production requires tag.
3. Rollback path documented.
4. Health reflects correct version.
5. Lock version matches Git tag.

-----------------------------------

FINAL OUTPUT FORMAT:

Return structured audit report:

{
  "overall_status": "PASS | CONDITIONAL | FAIL",
  "determinism": "PASS/FAIL",
  "immutability": "PASS/FAIL",
  "fail_closed_security": "PASS/FAIL",
  "injection_safety": "PASS/FAIL",
  "runtime_integrity": "PASS/FAIL",
  "governance_integrity": "PASS/FAIL",
  "deployment_integrity": "PASS/FAIL",
  "critical_findings": [],
  "recommendations": [],
  "enterprise_readiness_score": 0-100
}

Do not provide marketing language.
Be forensic.
Be strict.
Fail if uncertain.
